%%%%%%%%%%%%%%%%%%%% author.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample root file for your "contribution" to a contributed volume
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[graybox]{svmult}

% choose options for [] as required from the list
% in the Reference Guide

\usepackage{mathptmx}       % selects Times Roman as basic font
\usepackage{helvet}         % selects Helvetica as sans-serif font
\usepackage{courier}        % selects Courier as typewriter font
\usepackage{type1cm}        % activate if the above 3 fonts are
                            % not available on your system
%
\usepackage{makeidx}         % allows index generation
\usepackage{graphicx}        % standard LaTeX graphics tool
                             % when including figure files
\usepackage{multicol}        % used for the two-column index
\usepackage[bottom]{footmisc}% places footnotes at page bottom

\usepackage[sort&compress,numbers]{natbib}
\usepackage{todonotes}
\usepackage{amsmath, amsfonts}
\usepackage{blkarray}
\usepackage{xypic}

%% macros for the manuscript.... %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\partition}{\ensuremath{\mathbf{P}}}

%% Symbols for likelihoods
\newcommand{\G}{\ensuremath{G}}
\renewcommand{\D}{\ensuremath{D}}
\renewcommand{\lhd}{\ensuremath{\mathcal{L}}}
\newcommand{\T}{\ensuremath{\mathbf{T}}}
\renewcommand{\E}{\ensuremath{\mathbf{E}}}

\newcommand{\argmax}{\ensuremath{\operatorname*{arg\,max}}}
\newcommand{\intd}{\ensuremath{\mathrm{\;d\,}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% see the list of further useful packages
% in the Reference Guide

\makeindex             % used for the subject index
                       % please use the style svind.ist with
                       % your makeindex program

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title*{Ancestral population genomics with coalescent hidden Markov models}
\author{Jade Yu Cheng and Thomas Mailund}
\institute{Jade Yu Cheng \at FIXME
	\email{name@email.address}
\and Thomas Mailund \at Bioinformatics Research Centre, Aarhus University \email{mailund@birc.au.dk}}
\maketitle

\abstract{FIXME}


\section{Introduction}

Understanding how species form and diverge is a central topic of biology and by observing emerging species today we can understand many of the genetic and environmental processes involved. Through such observations we can understand the underlying forces that drive speciation, but in order to understand how specific speciations occurred in the past, and understand the specifics of how existing species formed, we must make inference from the signals these events have left behind. The study of fossils is a powerful approach here, but not the only avenue to study past speciations; the speciation processes leave fossils in the genome of the resulting species, and through what you might call genetic archaeology we can study past events from the signals they left behind.

Over the last three decades several inference methods were developed to model speciation and estimate the timing of splits, the presence or absence of gene-flow during a split, and estimate population genetics parameters of the ancestral species, such as the effective population size. For a detailed review of these, focusing on the human/chimpanzee speciation, we refer to~\citet{Mailund:2014fyb}.

Early methods considered short aligned segments and modelled how these would be different samples from the underlying coalescence process in the ancestral species~\cite{Takahata:1995kl, Innan:2006hc, Burgess:2008kf, Rannala:2003vt, Yang:2002wz, Yang:2006eu, Yang:2010fm, Becquet:2009hta, Chen:2001dka, Wall:2003vb}. Common for these is that recombination was not explicitly modelled, with the exception of the model of~\citet{Becquet:2009hta} that allows intra-locus recombination at a cost in computational complexity. The methods considered genomic regions sufficiently short that recombination was considered unlikely and sufficiently apart that the regions could be considered independent.

Sequencing technology, however, has progressed dramatically over the last decade and now multiple full genome sequences are readily available for many related species and constructing sequences for new species is affordable for even small research groups. To fully exploit such data, models will have to explicitly consider recombination. We have to move from ancestral population genetics to \emph{genomics}.


\subsection{The sequential Markov coalescent and coalescent hidden Markov models}

Models for ancestral population genetics are based on coalescence theory~\cite{Hein:2004ta} that describes the stochastic process of how lineages of a present day sample coalesce into common ancestors back in time. The outcome of this process, when both coalescence events and recombination events are considered, is called the \emph{ancestral recombination graph} or ARG. The coalescence process with recombination was originally described as a process running backward in time, but~\citet{Wiuf:1999gua} showed that it could also be modelled as a process running along a sequence alignment. This process, however, is computationally intractable for long sequences because it requires keeping track of all local gene trees along the sequence.

Considering the coalescence process as a sequential process along a sequence alignment lead to two innovations for modelling long sequence alignments experiencing recombination: the \emph{sequential Markov coalescence} and \emph{coalescent hidden Markov models}; two ideas that while starting out from different ideas have now largely merged.

The sequential Markov coalescence was introduced by~\citet{McVean:2005hoa} who considered a coalescence process where lineages are not allowed to coalesce unless they share ancestral material. They showed that this process would be Markov when considered as a sequential process and dubbed the process the sequential Markov coalescence, SMC. Because the model originated from restrictions on which lineages could coalesce, rather than an attempt to approximate the Wiuf \& Hein model as a Markov process, it does not allow two lineages resulting from a recombination to re-coalesce unless they have first coalesced with other lineages. Consequently, when there are few lineages a large fraction of the coalescence event that would be allowed in the coalescence process are not allowed in the SMC. This was amended by~\citet{Marjoram:2006hpa} in a model named SMC$^\prime$ that matches the SMC process except for explicitly allowing these back-coalescence events. This model was further extended to allow higher order Markov dependencies in the MaCS model by \citet{Chen:2009fga}. This early work on sequential Markov coalescence models focused on simulating sequence data and not on data analysis.

Independently of the work on sequential Markov coalescent models we developed a model for inferring the speciation dates of the human-chimpanzee and human-gorilla splits in \citet{Hobolth:2007gza}. While this model was based on ideas from \citet{Wiuf:1999gua}, combined with ideas from \citet{Takahata:1995kl}, it did not explicitly model the coalescence process. Instead it simply specified a hidden Markov model with gene genealogies as hidden states and fitted the rate of changes in these to a sequence alignment. Parameters from the coalescence process were then inferred based on the fitted hidden Markov model parameters. The term \emph{coalescent hidden Markov model}, or CoalHMM, was coined in this paper.

We later constructed a model that merges the coalescent hidden Markov model from \citet{Hobolth:2007gza} with the SMC model in \citet{Dutheil:2009dta}. This model was also applied to the human-chimpanzee and human-gorilla speciation and revealed very clearly that not allowing back-coalescences in the long time periods where all sequences are in isolated species would lead to a serious underestimation of the recombination rate.

To alleviate this we developed a new model that uses continuous time Markov chains (CTMCs) to explicitly model all recombination and coalescence events possible for a pair of neighbouring nucleotides and built a CoalHMM from this in \citet{Mailund:2011dva}. As an added benefit, this model allowed us to infer parameters from a pair of sequences, where the previous methods requires three sequences and incomplete lineage sorting between them.

Independent of this, Li \& Durbin developed a CoalHMM based on the SMC for pairs of sequences, the so-called pairwise sequential Markov coalescent model PSMC~\cite{Li:2011eza}, for inferring changing effective population sizes back in time. \citet{Paul:2010iba} and \citet{Paul:2011gva} developed a model combining the SMC with a conditional sampling approach to scale the data size beyond pairs, while \citet{Rasmussen:2014cqa} developed a sampling approach with the same aim.

A number of models followed these, extending the models to consider gene-flow patterns~\cite{Steinrucken:2013kba,Mailund:2012ewa}, changing population sizes~\cite{Sheehan:2013iba,Schiffels:2014cua} or inference of recombination patters, and selection \cite{Munch:2014cba, Munch:2014cwa}, \cite{Dutheil:2015kl, Munch:2016dn}, and CoalHMMs have been used in a number of whole genome analyses \cite{Locke:2011gna, Hobolth:2011dia, Scally:2012ika, Prufer:2012ea, Miller:2012cxa, Abascal:2016cy, PradoMartinez:2013dna, Jonsson:2014fga}.

In this chapter we will present the theory underlying our approach to constructing coalescent hidden Markov models and present our current implementations of various models and how you can apply these to your own genomic analyses.


\section{The coalescent process and the hidden Markov model approximation}

The sequential Markov coalescent and coalescent hidden Markov models aim to approximate the coalescent model with recombination in order to make analysis tractable. The coalescent model of population genetics describes the ancestry of a sample of observed genes and gives probabilities to all the possible genealogies that can explain the observation. The typical formulation of the model is as a continuous time Markov chain (CTMC) that describes how the sampled genes find common ancestors as we look further and further back in time. 

A (time homogeneous) continuous time Markov chain (CTMC) is a random process $\{\,X(t) \;|\; t \geq 0 \,\}$ where the infinitesimal rate of change between states at time $t$ is given by a \emph{rate matrix} $Q$: Let $\pi(t)$ be the vector of state probabilities $\pi(t)_i = \Pr(X(t)=i)$ then $\frac{\mathrm{d}\,\pi(t)}{\mathrm{d}\,t} = \pi(t)Q$. The off-diagonal entries of $Q$ contains the rates at which the system changes state, so $Q_{i,j}$ is the rate of change from state $i$ to state $j$, and the diagonal entries are given by $Q_{i,i} = - \sum_{j\neq i} Q_{i,j}$. The probability of going from state $i$ at time $s$ to state $j$ at time $t>s$ in such a system is given by $\Pr(X(t)=j\,|\,X(s)=i) = \left[\exp\left(Q\left(t-s\right)\right)\right]_{i,j}$ and given an initial probability vector $\pi(0)$ the probability vector at time $t\geq 0$ is given by $\pi(t)=\pi(0)\exp(Qt)$.

There is a rich theory for CTMCs so expressing systems in terms of these gives us a very powerful framework to work in. The key property we will use is the way of computing the transition probabilities $\Pr(X(t)=j\,|\,X(s)=i)$ using matrix exponentiation $\exp\left(Q\left(t-s\right)\right)$. This can be done fully automatically---several algorithms exists and matrix exponentiation is implemented in many numerical software packages \cite{Moler2003}---and it greatly simplifies the mathematical modelling---see e.g.\ \citet{Hobolth:2011hl} and \citet{Andersen:2013iz} for examples of where matrix exponentiation simplifies otherwise rather complex computations.

Constructing a CTMC consists of specifying the rate matrix $Q$ and the initial probability vector $\pi(0)$. In most cases this is relatively straightforward, mathematically at least; explicitly specifying the rate matrix can be problematic when the state space is very large. When the state space is large it becomes necessary to automatically generate it and construct the rate matrix. In the remainder of this section, we describe how to automatically construct CTMCs capturing the coalescence process and how these can then be used to construct coalescent hidden Markov models.

\subsection{The coalescence process and continuous time Markov chains}

In the coalescence model, the CTMC runs backwards in time, and if we ignore for a second that lineages can undergo recombination or be part of a structured population, the only events we observe are when two lineage coalesce into a common ancestor. If we ignore the identity of the genes, and we start with $n$ genes, the states of the system can be represented by numbers from $1$ to $n$, $k=1,2,\ldots,n$, and the system will have transitions $k\to k-1$ for $k>1$ occurring with rate $c{k \choose 2}$ where $c$ is the rate at which pairs of lineages coalesce, a parameter that is determined by the size of the population the samples are taken from (the so-called ``effective population size'', $2N_e$, or its mutation-scaled version $\theta=4 N_e \mu$, see \citet{Hein:2004ta}). Any pair of lineages will coalesce with rate $c$, so with $k$ lineages there are $k \choose 2$ pairs and thus the rate of change is $c{k \choose 2}$. We start in the state $n$ and we typically run this process until we are left with a single lineage at which point we have a tree genealogy explaining the observed genes. This process lets us sample genealogies, and we can later randomly assign gene labels to leaves in sampled trees and assign mutations to edges on the trees to explain variation in the observed genes.

\todo[inline]{Make a good illustration of a coalescence tree.}

First simulating genealogies and then assigning identity to the leaves is only a valid approach if there is complete symmetry between the genes, however. Several variations on the coalescence process can break this symmetry. If the genes are sampled from a structured population, for example, the rate of coalescence will depend on which pair of lineages coalesce. Without complicating the process with population structure yet, we can preserve lineage identity in a finite state CTMC by representing states by more than the number of lineages. We will explicitly model the identity of ancestral lineages by tagging them with the genes they are ancestral to. If we let $S=\{\,1,2,\ldots,n\,\}$ denote the set of genes, then any subset $L\subseteq S$ can be thought of as an ancestral lineage, ancestral to the genes in $L$.

If we let $\partition\left(S\right)$ denote the set of partitions of a set $S$, i.e.\ the set of all sets $P=\{\,x_1,x_2,\ldots,x_k\,\}$ such that $x_i\cap x_j=\emptyset$, $x_i\neq\emptyset$, and $\bigcup_i x_i = S$, then any element $P\in\partition\left(S\right)$ corresponds to a set of ancestral lineages of $S$. A natural way to model the coalescence process as a finite state CTMC is thus to use $\partition\left(S\right)$ as the set of states. The process will start in the partition where each sample is a singleton, $\{\,\{i\}\;|\;i=1,\ldots,n\,\}$, and finish in the state where all samples have merged into the same lineage, $\{\,S\,\}$. The transitions of the CTMC will go from one partition to another and capture coalescence events. For each partition $P=\{\,x_1,x_2,\ldots,x_k\,\}$ we can pick out two lineages, $x_i$ and $x_j$, and merge them into one, $x_i\cup x_j$, to create the partition $P'=\{\,x_i\cup x_j,x_1,\ldots,x_{i-1},x_{i+1},\ldots,x_{j-1},x_{j+1},\ldots,x_k\,\}$. In the transition system view we see this as a transition $P\to P'$. This particular transition, that merges lineages $x_i$ with $x_j$, occurs with rate $c$---the rate at which a \emph{specific} pair of lineages coalesce. Since a partition with $k$ elements will have $k \choose 2$ pairs to choose from, the rate out of any state with $k$ lineages will still be $c{k \choose 2}$, but with this model of the process we explicitly keep track of which lineages each sampled gene belongs to; at the cost of having a much larger state space, of course.

\todo[inline]{Insert Figure 1 from thesis here}

Using the CTMC formulation of the coalescence process we can easily compute the density of any given genealogy, $f(\G\,|\,\Theta)$, given the parameters of the CTMC, $\Theta$, (in the simple coalescence process we have described here, the only parameter is the coalescence rate, $\Theta = \left\{c\right\}$). Given a genealogy, it is also straightforward to get the probability of observing our data, the sampled genes, $\D$: $\Pr(\D\,|\,\G,\Theta)$. This probability depends on the mutation model and a simple approach is to sum over all possible sequences at internal nodes using standard methods such as Felsenstein's peeling algorithm \cite{Felsenstein_1981}. Then, the substitution model might contain more parameters as part of $\Theta$. In our approach, though, we use a Jukes-Cantor model and we scale time (via the coalescence rate $c$) in units of substitutions, so we have no additional parameters for mutations, but nothing prevents you from using other models.

More complex demographics scenarios can be modelled and their parameters will be part of $\Theta$, and in many applications it is these parameters that are of interest rather than the actual underlying genealogy, which is considered a nuisance parameter to be integrated out to get the likelihood:

\begin{equation}
	\label{eq:likelihood-integral}
    \lhd(\Theta\,|\,\D) = \int f(\D\,|\,\G,\Theta) f(\G\,|\,\Theta) \intd\G .
\end{equation}

This integral over all possible genealogies is generally not efficiently computable and must either be approximated through sampling approaches or by approximating the coalescence process with a simpler model where the integral \emph{can} be computed. 


\subsection{The coalescent with recombination}

When adding recombination to the coalescent process, we give genes length. Without recombination, we simply model genes as atomic entities with lineages going back in time; with recombination, the genes have a length dimension and the ancestry of genes can break up into several lineages as we move into the past.

If we model lineages as consisting of a finite length of nucleotides we can have lineage $x$ represented as $x=(x_1,x_2,\ldots,x_L)$ where each $x_i$ is a subset of the set of samples. Each $x_i$ plays the role of a single lineage when we model the process without recombination; it consists of the samples that have lineage $x$ as a common ancestor at the $i$'th locus. A state of the CTMC will consist of a set of such lineages---and to ensure that this state space is finite we require that for all lineages $x$ at least some $x_i$s are non-empty---such that the $i$'th index sets are disjunct and such that the union of all $i$'th index sets is the full set of samples. We do not require that the $i$'th index sets are partitions of the set of samples; some can be empty sets. The non-empty sets we call \emph{ancestral material}. These represent genetic material that is ancestral to some of the samples we are modelling the ancestry of. We require that all lineages we consider contain some ancestral material.

Pairs of lineages can coalesce, similar to how it was modelled without recombination, and individual lineages can recombine into two lineages. A coalescence event would take two lineages, $x=(x_1,\ldots,x_L)$ and $y=(y_1,\ldots,y_L)$, and produce the lineage $z=(x_1\cup y_1,\ldots,x_L\cup y_L)$. A recombination event would take one lineage $x=(x_1,\ldots,x_L)$ and pick a recombination point $k: 1 \leq k < L$. It would then produce two lineages $(x_1,\ldots,x_k,\emptyset,\ldots,\emptyset)$ and $(\emptyset,\ldots,\emptyset,x_{k+1},\ldots,x_L)$ where the ancestral material up to point $k$ is put in the first lineage and the ancestral material after point $k$ is put in the second lineage, and where we would restrict constructed lineages so recombination does not produce lineages without any ancestral material.


\todo[inline]{Make a good illustration of recombining lineages.}

Since this is another CTMC we can, in principle, compute the density of all genealogies, $f(\G\,|\,\Theta)$. We generally will assume that mutations at individual sites are independent, so we can compute the probability of the data conditional on the genealogy site-wise
\begin{equation}
  \Pr(\D\,|\,\G,\Theta) =
  \prod_{i=1}^L \Pr(\D_i\,|\,\G_i,\Theta)
\end{equation}
where $\D_i$ denote the variation at site $i$ and $\G_i$ the genealogy at site $i$.

In practice, however, the state space for this CTMC makes this approach intractable when it comes to integrate over all genealogies as in \eqref{eq:likelihood-integral}. While the integral in \eqref{eq:likelihood-integral} itself often requires sampling or approximations to compute, it is often doable. The larger state space in the process with recombination makes the integration infeasible for all but the smallest sequences and smallest sample sizes.


\subsection{The hidden Markov model approximation}

The sequential Markov coalescence approximates the coalescence process with recombination by assuming that the dependencies between genealogies is Markov:

\begin{equation}
  \label{eq:markov-genealogy}
  f(\G\,|\,\Theta) \approx
  f(\G_1\,|\,\Theta)\prod_{i=2}^{L}f(\G_{i}\,|\,\G_{i-1},\Theta)
  .
\end{equation}

With this approximation, the joint density of data and genealogies become
\begin{equation}
  \label{eq:coalhmm-joint-probability}
  f(\D,\G\,|\,\Theta) = 
  	f(\G_1\,|\,\Theta)
  	\prod_{i=2}^{L}f(\G_{i}\,|\,\G_{i-1},\Theta)
  	\prod_{i=1}^L \Pr(\D_i\,|\,\G_i,\Theta)
  	,
\end{equation}
which is characteristic of \emph{hidden Markov models}, stochastic models of sequences formulated as joint probabilities of a \emph{hidden} sequence $\mathbf{Z}=(Z_1,Z_2,\ldots,Z_L)$ and an \emph{observed} sequence $\mathbf{X}=(X_1,X_2,\ldots,X_L)$ where the dependencies between the hidden states, $Z_i$, is Markov and the observed states, $X_i$, are independent conditional on the hidden states, and the joint probability is
\begin{align}
  \Pr(\mathbf{X},\mathbf{Z})
    &= 
  	\Pr(Z_1)
  	\prod_{i=2}^{L}\Pr(Z_{i}\,|\,Z_{i-1})
  	\prod_{i=1}^L \Pr(X_i\,|\,Z_i)
  	\\
    \label{eq:hmm-joint-probability}
  	&=
  	\pi_{Z_1}
  	\prod_{i=2}^{L}\T_{Z_{i-1},Z_{i}}
  	\prod_{i=1}^L  \E_{Z_i,X_i}
\end{align}
where in \eqref{eq:hmm-joint-probability} $\pi$ denotes a vector of \emph{initial state probabilities}, $\T$ a matrix of \emph{transition probabilities}, and $\E$ a matrix of \emph{emission probabilities}.\footnote{The intuition is that the $\mathbf{Z}$ sequence is not observed but each $Z_i$ emits a symbol, $X_i$ that \emph{is} observed.}

The form of \eqref{eq:coalhmm-joint-probability} closely resembles \eqref{eq:hmm-joint-probability} except that the matrix representation for the hidden Markov model requires the state space to be finite, which the set of all possible local coalescent genealogies is not. The branch lengths of genealogies are real numbers, thus there are infinitely many genealogies. To approximate the coalescent with recombination we employ another approximation and discretise time. We divide the real line into $m$ time points and require that all coalescence event occur in one of those.

Constructing hidden Markov models therefore consist of constructing the initial state probability vector
\begin{equation}
  \label{eq:initial_prob}
  \pi_{\G_1} = \Pr(\G_1\,|\,\Theta),
\end{equation}
the transition probability matrix
\begin{equation}
  \label{eq:transition_prob}
  \T_{\G_{i-1},\G_i} = \Pr(\G_i\,|\,\G_{i-1},\Theta),
\end{equation}
and the emission probability matrix
\begin{equation}
  \E_{\G_i,\D_i} = \Pr(\D_i\,|\,\G_i,\Theta)
\end{equation}
to capture as well as possible under the approximation the probabilities we would see given the parameters $\Theta$. (In \eqref{eq:initial_prob} and \eqref{eq:transition_prob} we have replaced densities, $f(-)$, with probabilities, $\Pr(-)$, to indicate that we have discretised the set of genealogies).

The emission probabilities can be computed using standard substitution models and algorithms, and we will not describe this further. For the initial states and transition probabilities we get these from the joint probability of two neighbouring genealogies, $\Pr(\G_i,\G_{i+1})$ (where we assume that the Markov model in \eqref{eq:markov-genealogy} is homogeneous and this probability thus the same for all $i$). From this joint probability we can marginalise and get
\begin{equation} \label{eq:pi-from-joint-prob}
  \Pr(\G_i) = \sum_{\G_{i+1}} \Pr(\G_i,\G_{i+1})
\end{equation}
and we set $\pi_{\G_1}=\Pr(\G_1)$ and 
\begin{equation} \label{eq:transitions-from-joint-prob}
  \T_{\G_{i-1},\G_i} = \frac{\Pr(\G_{i-1},\G_i)}{\Pr(\G_{i-1})}.
\end{equation}

The crux of the construction is thus computing $\Pr(\G_i,\G_{i+1})$, which we describe in the next section.

An important point to make first, however, is that by formulating the model as a hidden Markov model we obtain a number of efficient algorithms for parameter estimation and for decoding the most likely hidden genealogies. For example, to compute the likelihood of the model, the discretisation changes the integral from \eqref{eq:likelihood-integral} to the sum
\begin{equation}
  \label{eq:likelhood-sum}
  \lhd(\Theta\,|\,\D) = 
  \sum_{\G=(\G_1,\G_2,\ldots,\G_L)} 
  	\left[
   	  \pi_{\G_1}
  	  \prod_{i=2}^{L}\T_{\G_{i-1},\G_{i}}
  	  \prod_{i=1}^L  \E_{\G_i,\D_i}
  	\right]
\end{equation}
which in this form involves summing over a sum with an exponential number of terms as a function of $L$, but which can be computed in time $O(N^2L)$ using dynamic programming, where $N$ is the number of hidden states, i.e.\ the number of genealogies. The algorithm, known as the \emph{forward} algorithm, defines $F(g,i)$ to be the probability of being in genealogy $g$ at index $i$ and having observed $(\D_1,\ldots,\D_i)$. This function can be computed recursively
\begin{equation}
  F(g,i) = 
  \begin{cases}
  	\pi_g & i = 1 \\
  	\E_{g,\D_i} \times \sum_{\G_{i-1}}\T_{\G_{i-1},g} \times F(\G_{i-1},i-1)
  	& \mathrm{otherwise}
  \end{cases}
\end{equation}
and the recursion can be replaced by dynamic programming, where we fill a table \texttt{F} with $\mathtt{F}[g,1] = \pi_g$ for all $g$ and then from $i=2$ to $i=L$ compute
\[
\mathtt{F}[g,i] = \E_{g,\D_i} \times \sum_{\G_{i-1}}\T_{\G_{i-1},g} \times \mathtt{F}[\G_{i-1},i-1]
\]
for all $g$. The \texttt{F} table has $N\times L$ entires and computing each recursive entry requires a sum over $N$ elements, giving us a running time of $O(N^2L)$. Once \texttt{F} has been filled, we can get the likelihood by summing over all final genealogies:
\begin{equation}
  \lhd(\Theta\,|\,\D) = \sum_{g} \mathtt{F}[g,L].
\end{equation}


\section{Constructing coalescent hidden Markov models}

To construct a hidden Markov model to approximate the coalescence process for a given demographic model, with a given set of associated parameters, we must construct the HMM parameters: the tuple $(\pi,\T,\E)$. As seen in \eqref{eq:pi-from-joint-prob} and \eqref{eq:transitions-from-joint-prob}, we can derive $\pi$ and $\T$ from joint probabilities of two genealogies, and as mentioned earlier, we can compute $\E$ from standard algorithms (once we have discretised time), so the crux of deriving the CoalHMM is computing probabilities $\Pr(G_i,G_{i+1})$. This, we can compute from the CTMC that models the coalescence process in the given demography; if we know how the CTMC that models the lineages of two neighbouring nucleotides change over time, we can extract the two neighbouring genealogies from it.

We need a finite number of genealogies to construct a finite $\pi$ vector and a finite $\T$ matrix, so we first discretise time. Let $(\tau_1=0,\tau_2,\ldots,\tau_m)$ be $m$ time points with $\tau_i<\tau_{i+1}$. We discretise time by only considering the CTMC states at these specific time points. Any coalescences that occur between two of these points we place at a time point $\sigma_i: \tau_i < \sigma_i < \tau_{i+1}$ for $1 \leq i < m$ and if we have lineages that haven't found their most recent common ancestor at time $\tau_{m}$ we assume they happen at a $\sigma_m > \tau_m$. There are multiple ways to pick both time points $\tau_i$ and $\sigma_i$; in our software we use heuristics described in \citet{Mailund:2011dva} and \cite{Mailund:2012ewa}, but as the number of time points increase, so the discretisation gets finer, the choice of discretisation gets less important.

With this discretisation, we can define a genealogy by which partitions of lineages we have at each of the $\tau_i$ time points: a \emph{genealogy} $G$ is a sequence of partitions of lineages, $(p_1,p_2,\ldots,p_m)$, such that each lineage in $p_i$ can be formed from the union of one or more lineages in $p_{i-1}$. Now, given two such genealogies, $G$ and $G'$, with partitions at the $m$ $\tau_i$ points $(p_1,p_2,\ldots,p_m)$ and $(p'_1,p'_2,\ldots,p'_m)$, we want to know the joint probability $\Pr(G_i=G,G_{i+1}=G')$. We can \emph{almost} get this from a CTMC modelling the coalescence process. If we denote the CTMC by $\left\{ X(t) \,|\, t\geq 0 \right\}$, then we can compute the likelihood that it is in specific states at each $\tau_i$ as this,
\begin{equation}
	\Pr(X(\tau_1)=x_1,X(\tau_2)=x_2,\ldots,X(\tau_m)=x_m) =
	\prod_{i=1}^{m-1} \exp\left(Q\left(\tau_{i+1}-\tau_i\right)\right)_{x_i,x_{i+1}}
\end{equation}
where $Q$ is the rate matrix for the CTMC. The states in the CTMC, however, contain more information than what we can see from the two genealogies. The states in the CTMC contain information about which lineages on the left genealogy are linked to which lineages on the right genealogy. If we only know which lineages are in the left and which are in the right genealogy at any given $\tau_i$ time point, we do not have this information.

Consider the simplest non-trivial example of two samples from one population. Its states are shown in Table~\ref{tbl:psmc-like-ctmc}, where black dots at the top and bottom refers to sample one and two, respectively, and white circles refer to common ancestors. Lines between lineages on the left and right indicates that the left and right nucleotides are linked, i.e.\ on the same chromosome, while the absence of lines indicate that they are not. It is the CTMC we can define by starting in state $\{(\{1\},\{1\}),(\{2\},\{2\})\}$ and following the rules\todo{Should we define transition systems earlier and refer to that here, or keep at this semi-formal/informal level?}
\begin{itemize}
	\item $\{(l_1,r_1)\}\cup\{(l_2,r_2)\}\cup\text{Rest} \overset{C}{\to}\{(l_1\cup l_2,r_1 \cup r_2)\}\cup\text{Rest}$ 
	\item $\{(l,r)\}\cup\text{Rest} \overset{R}{\to} \{(l,\emptyset)\}\cup\{(\emptyset,r)\}\cup\text{Rest}$ if $l\neq\emptyset$ and $r\neq\emptyset$.
\end{itemize}
Read the first rule as lineage $(l_1,r_1)$ coalesces with lineage $(r_1,r_2)$ at rate $C$ while leaving the rest of the lineages unchanged. Read the second as the lineage $(l,r)$ recombining at rate $R$, while leaving the rest of the lineages unchanged, but only if both $l$ and $r$ are non-empty, i.e.\ as long as we have ancestral material both to the left and to the right of the recombination point.

\begin{table}[tb]
  \caption{CTMC states for two samples in the same population.}
  \label{tbl:psmc-like-ctmc}
  \centering
  \scalebox{.7}{
  \begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
    Index & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15\\ \hline
    State & 
    % 1
    $\xymatrix @R=0.5pc @C=0.5pc {
      \bullet & \bullet \\
      \bullet & \bullet }$ & 
    % 2
    $\xymatrix @R=0.5pc @C=0.5pc {
      \bullet \ar@{-}[r] & \bullet \\
      \bullet & \bullet }$ &
    % 3
    $\xymatrix @R=0.5pc @C=0.5pc {
      \bullet & \bullet \\
      \bullet \ar@{-}[r] & \bullet }$ &
    % 4
    $\xymatrix @R=0.5pc @C=0.5pc {
      \bullet \ar@{-}[r] & \bullet \\
      \bullet \ar@{-}[r] & \bullet }$ &
    % 5
    $\xymatrix @R=0.5pc @C=0.5pc {
      \bullet \ar@{-}[dr] & \bullet \\
      \bullet  & \bullet }$ &
    % 6
    $\xymatrix @R=0.5pc @C=0.5pc {
      \bullet  & \bullet \\
      \bullet \ar@{-}[ur] & \bullet }$ &
    % 7
    $\xymatrix @R=0.5pc @C=0.5pc {
      \bullet \ar@{-}[dr] & \bullet \\
      \bullet \ar@{-}[ur] & \bullet }$ &

    % 8
    $\xymatrix @R=0.1pc @C=0.5pc {
            & \bullet \\
      \circ &  \\
            & \bullet }$ &
    % 9 
    $\xymatrix @R=0.1pc @C=0.5pc {
                    & \bullet \\
   {\circ} \ar@{-}[ur] & \\
                    & \bullet }$ &    
    % 10
    $\xymatrix @R=0.1pc @C=0.5pc {
      & \bullet \\
      \circ \ar@{-}[dr] &\\
      & \bullet} $ &

    % 11 
    $\xymatrix @R=0.1pc @C=0.5pc {
      \bullet & \\
      & \circ  \\
      \bullet} $ &
    % 12
    $\xymatrix @R=0.1pc @C=0.5pc {
      \bullet \ar@{-}[dr] &  \\
      & \circ\\
      \bullet }$ &
    % 13
    $\xymatrix @R=0.1pc @C=0.5pc {
      \bullet &  \\
      & \circ \\
      \bullet \ar@{-}[ur] }$ &
      
    % 14
    $\xymatrix @R=0.5pc @C=0.5pc {
      \circ \ar@{-}[r] & \circ }$ &
    % 15
    $\xymatrix @R=0.5pc @C=0.5pc {
      \circ & \circ }$ \\ \hline
    Classes & \multicolumn{7}{c|}{$N$} &
    \multicolumn{3}{c|}{$L$} &
    \multicolumn{3}{c|}{$R$} &
    \multicolumn{2}{c}{$B$}
  \end{tabular}
  }
\end{table}


The transition rules define not only the state space of the CTMC but also the its rate matrix. All non-diagonal cells will be rates equal to one of $C$, $R$, or zero. Entry $Q_{i,j}$ will be $C$ when you can get from state $i$ to state $j$ following the first rule, $R$ when you can get from $i$ to $j$ by following the second rule. If there are no direct rule to get you from $i$ to $j$, the instantaneous rate, and thus $Q_{i,j}$, is zero. The rate matrix looks like this:
\begin{equation}
  \label{eq:two-samples-ctmc}
  Q = 
\begin{blockarray}{lccccccccccccccc}
	\quad\;\;
 & \BAmulticolumn{7}{c}{N} & \BAmulticolumn{3}{c}{L} & \BAmulticolumn{3}{c}{R} & \BAmulticolumn{2}{c}{B} \\
\begin{block}{l(ccccccc|ccc|ccc|cc)}
  & - & C & C &   & C & C &   & C &   &   & C &   &   &   &   \\
  & R & - &   & C &    &     &   &   & C &   &   & C &   &   &   \\
  & R &   & - & C &   &   &   &   &  & C &   &   & C &   &   \\
  N &   & R & R & - &   &   &   &   &  &   &   &   &   & C &   \\ 
  & R &   &   &   & - &   & C &  &   & C &   & C &   &   &   \\
  & R &   &   &   &   & - & C &   & C &   &   &   & C &   &  \\
  &   &   &   &   & R & R & - &   &   &   &   &   &   & C &   \\
  \BAhhline{&---------------}
   & &   &   &  &   &   &   & - & C & C &   &   &   &   & C \\
  L & &   &   &  &   &   &   & R & - &   &   &   &   & C &   \\
   & &   &   &  &   &   &   & R &   & - &   &   &   & C &   \\ 
  \BAhhline{&---------------}
   & &   &   &  &   &   &   &   &   &   & - & C & C &   & C \\
  R & &   &   &  &   &   &   &   &   &   & R & - &   & C &   \\
   & &   &   &  &   &   &   &   &   &   & R &   & - & C &   \\ 
  \BAhhline{&---------------}
  B & &   &   &  &   &   &   &   &   &   &   &   &   & - & R \\
   & &   &   &  &   &   &   &   &   &   &   &   &   & C & - \\
\end{block}
\end{blockarray}
\end{equation}

If we only know the lineages that exists at the left and right nucleotide, respectively, there are equivalence classes of states that we cannot distinguish. In the table and the matrix these are named $N$ (for no MRCA), $L$ (for when only the left nucleotide has reached the MRCA), $R$ (for when only the right nucleotide), and $B$ (for when both have). If we know the the left and right genealogies, we will know for each time point $\tau_i$ which class the CTMC state is in, but not the exact state. To compute the probability of two genealogies, we need to sum over the states in each equivalence class.


For a two-nucleotide CTMC, each lineage is a pair of (possibly empty) sets of initial samples. If we extract the left or right nucleotides of all lineages in a CTMC state $s$, we would in both cases get a partitioning of the original samples---call those $l(s)$ and $r(s)$, respectively. It is these pairs that define the equivalence classes; any two states $s$ and $s'$ with $l(s)=l(s')$ and $r(s)=r(s')$ are equivalent. For the simple case we have just considered, $N$ is the equivalence class defined by $l=\{\{1\},\{2\}\}$ and $r=\{\{1\},\{2\}\}$, $L$ has $l=\{\{1,2\}\}$ and $r=\{\{1\},\{2\}\}$, $R$ has those partitions flipped, and $B$ has both $l=\{\{1,2\}\}$ and $r=\{\{1,2\}\}$.

For a pair of genealogies $G=(p_1,p_2,\ldots,p_m)$ and $G'=(p'_1,p'_2,\ldots,p'_m)$, pairing them up component wise gives is a sequence of CTMC equivalence classes $(c_1=(p_1,p'_1),c_2(p_2,p'_2),\ldots,c_m=(p_m,p'_m))$. The joint probability of the two genealogies can then be obtained from the CTMC as this:
\begin{eqnarray}
	\Pr(G_i=G,G_{i+1}=G') &=& 
	\Pr(X(\tau_1)\in c_1,X(\tau_2)\in c_2,\ldots,X(\tau_m)\in c_m) \\
	&=& 
	\label{eq:ctmc-probability-of-joint-genealogies}
	\sum_{x_1\in c_1}\sum_{x_2\in c_2}\cdots\sum_{x_m\in c_m}
	\prod_{i=1}^{m-1} \exp\left(Q\left(\tau_{i+1}-\tau_i\right)\right)_{x_i,x_{i+1}}
\end{eqnarray}
and the sum and products can be rearranged---similar to how it is done for hidden Markov models---to produce a dynamic programming algorithm that lets us computed the joint probability efficiently.

While this framework might seem complicated, from \eqref{eq:ctmc-probability-of-joint-genealogies} it should be obvious that we can automatically derive a CoalHMM as long as we have the rate matrix of a CTMC modelling the demography of interest, $Q$, and a discretisation of time $(\tau_1,\ldots,\tau_m)$.


\section{Modelling demography as sequences of CTMCs}

To actually capture demographies, we must make two slight changes to \eqref{eq:ctmc-probability-of-joint-genealogies}; the first allows us to vary parameters of the demography for different time periods and the second allows us to model population changes, such as moving from isolation periods to migration periods, to split populations into descendant populations, or model admixture events. Equation \eqref{eq:ctmc-probability-of-joint-genealogies} uses the same rate matrix in all time intervals, but this assumes no demographic changes. The first modification we do is to associate each time interval with its own rate matrix:
\begin{equation}
	\Pr(G_i=G,G_{i+1}=G') =
	\prod_{i=1}^{m-1} \exp\left(Q_i\left(\tau_{i+1}-\tau_i\right)\right)_{x_i,x_{i+1}}
	.
\end{equation}

In practise, we cannot have distinct rate matrices for each time interval; we would not be able to infer the parameters if we did. Instead, we use the same matrix for some consecutive intervals, as was done with Li and Durbin's PSMC model for inferring changes to effective population sizes over time \cite{Li:2011eza}. Since effective population sizes are inversely proportional to coalescence rates, in order to implement PSMC in the framework we have just presented, we would only need to modify the rate matrix in \eqref{eq:two-samples-ctmc} such that the coalescence rate $C$ depends on which time interval we consider.

A CTMC that models two populations and allow migration of lineages between them can be constructed in a similar way \cite{Mailund:2012ewa} and by varying migration rates between different time intervals, we can infer changes to migration rates over time \cite{Cheng:2015kia} (although with less inference accuracy). 

To model multiple populations, we tag each lineage with which population it is in. Instead of representing lineages as pairs of left and right nucleotides, we represent them as triplets $(p,l,r)$ of population, left and right nucleotide.

We modify the two transition rules we saw before to include population information and to only allow coalesce events between lineages lineages in the same population:
\begin{itemize}
	\item $\{(p_1,l_1,r_1)\}\cup\{(p_2,l_2,r_2)\}\cup\text{Rest} \overset{C}{\to}\{(p_1,l_1\cup l_2,r_1 \cup r_2)\}\cup\text{Rest}$ if $p_1=p_2$
	\item $\{(p,l,r)\}\cup\text{Rest} \overset{R}{\to} \{(p,l,\emptyset)\}\cup\{(p,\emptyset,r)\}\cup\text{Rest}$ if $l\neq\emptyset$ and $r\neq\emptyset$.
\end{itemize}
If we want to allow (continuous) migration from population $i$ to $j$ (when going back in time, i.e.\ from $j$ to $i$ when going forward in time), we add the rule
\begin{itemize}
	\item $\{(p_i,l,r)\}\cup\text{Rest} \overset{M_{i,j}}{\to} \{(p_j,l,r)\}\cup\text{Rest}$.
\end{itemize}
We can add rules for migrations between any pair of populations and make the rates symmetric or asymmetric.

In practise, the state space of the CTMC grows very quickly with more populations, so we have only worked with two populations in practise. In \citet{Mailund:2012ewa} with a single, symmetric, migration between the populations and in \citet{Cheng:2015kia} with a few periods of different rates.

We can combine isolation models---where lineages cannot move from one population to another---with migration models---where they can, by setting migration rates to zero in some time intervals. We cannot, however, construct the isolation model of \citet{Mailund:2011dva} or the isolation with initial migration model of \citet{Mailund:2012ewa} just by modifying rates in the same rate matrix. Both models have two populations in the presence, but at some point in the past, those split from an ancestral population. Tracing lineages back in time, the CTMC must at some instantaneous time-point move all lineages to this ancestral population.

In general, we can have different CTMCs with different state spaces before and after time $\tau_i$. To deal with this, we introduce a matrix $\eta^i$ that maps from the state space immediately before $\tau_i$ to the state space immediately after. The entry $\eta^i_{s,t}$ should be the probability that state $s$ maps to state $t$. We use this $\eta^i$ to modify \eqref{eq:ctmc-probability-of-joint-genealogies} to
\begin{equation}
	\Pr(G_i=G,G_{i+1}=G') = 
	\sum_{x_1\in c_1}\sum_{x_2\in c_2}\cdots\sum_{x_m\in c_m}
	\prod_{i=1}^{m-1} \left[\exp\left(Q\left(\tau_{i+1}-\tau_i\right)\right)\eta^i\right]_{x_i,x_{i+1}}
\end{equation}


There are some restrictions on $\eta^i$ since we want to ensure that each original sample is preserved in some ancestral lineage with probability one on both the left and the right nucleotides. One way to ensure this is to construct the matrix from a mapping of individual lineages.

Consider the model from \citet{Mailund:2012ewa}\todo{add a figure for the model}\ that has an initial period with two populations and no migration between them, followed (when looking back in time) by a period with migration, and at last a third period in an ancestral population. We will model lineages as triplets $(p,l,r)$ and consider there to be three populations, $p_1$, $p_2$ and $p_A$ where $p_A$ is the ancestral population. In the first period, we do not allow migration, so at the instant we move from that period to the one where we do, all lineages will be in the same population they started in. The lineage $(p,l,r)$ will map to $(p,l,r)$ with probability one. It looks a little like nothing changes, but the state spaces actually do. There are more possible states in the second period than in the first. When considering the entire state of the CTMC, it consists of a set of lineages, and each map to one other lineage---itself but in the other state space---so the resulting state is the set you get by mapping all the elements in the first state. The mapping $\eta$ is an injection. It maps each point in a subset of the second state space to itself.

When we move from the second to the third period, all lineages should change their population to $p_A$, so $(p,l,r)\mapsto(p_A,l,r)$ with probability one for all lineages. Again, we derive the mapping from state to state from this mapping between lineages by just applying the mapping to each lineage in each state. This $\eta$ is slightly different than the first since this one maps from a larger state space into a smaller. It is more like a projection than an injection. For both mappings, each state maps to one unique other state with probability one, but for the second mapping, several input states will map to the same output state.

We will not always map each state to a single other state with probability one; sometimes there is a distribution of states we map to. Consider an admixture event where two populations, $p_1$ and $p_2$, admix to become population $p_3$.\todo{Make a figure for this}\ If $p_3$ is created with fraction $\alpha$ of its population from $p_1$ and $1-\alpha$ from $p_2$, then a lineage $(p_3,l,r)$ will map to $(p_1,l,r)$ with probability $\alpha$ and to $(p_2,l,r)$ with probability $1-\alpha$. The probabilities associated with which lineages map to which carries over to states. State $s$ maps to state $t$ with probability $P$ if $t$ is the result of mapping the individual lineages in $s$ and $P$ is the product of the individual lineage mappings used.\todo{Give an admixture example}



\section{Using Jocx, a CoalHMM inference tool}
\todo[inline]{This is probably where we should describe that we only look at pairs and then use a composite likelihood}
\todo[inline]{Tutorial in how to use the software}

\section{CoalHMM results (better title)}
\todo[inline]{Some simulation results}


\bibliographystyle{spbasic}
\bibliography{references.bib}

\end{document}
